{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets, model_selection, metrics\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pedir el nombre del objeto\n",
    "object_name = input(\"Introduce el nombre del objeto: \")\n",
    "\n",
    "# Crear la carpeta si no existe\n",
    "if not os.path.exists(object_name):\n",
    "    os.makedirs(object_name)\n",
    "\n",
    "# Iniciar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "image_count = len(os.listdir(object_name))  # Contar el número de imágenes existentes en la carpeta\n",
    "\n",
    "while True:\n",
    "    # Capturar frame por frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Mostrar el frame resultante\n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    # Verificar si se presionó la tecla 'e' para guardar las imágenes\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'):\n",
    "        for i in range(15):  # Tomar 5 fotos\n",
    "            ret, frame = cap.read()\n",
    "            cv2.imwrite(f\"{object_name}/image_{image_count}.jpg\", frame)\n",
    "            image_count += 1\n",
    "    \n",
    "    # Salir con la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar la cámara y cerrar todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 20s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 14s 5s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 14s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 13s 4s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Función para cargar imágenes desde una carpeta y aplicar la máscara\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            # Convertir la imagen a escala de grises\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Aplicar un umbral para crear una máscara binaria\n",
    "            _, mask = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "            \n",
    "            # Encontrar contornos\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            # Encontrar el contorno más grande\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            \n",
    "            # Crear una máscara con el contorno más grande\n",
    "            object_mask = np.zeros_like(mask)\n",
    "            cv2.drawContours(object_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "            \n",
    "            # Aplicar la máscara a la imagen original\n",
    "            object_only = cv2.bitwise_and(img, img, mask=object_mask)\n",
    "            \n",
    "            # Añadir la imagen procesada y la etiqueta a las listas\n",
    "            images.append(object_only)\n",
    "            labels.append(folder)\n",
    "    return images, labels\n",
    "\n",
    "# Pedir el nombre de la carpeta\n",
    "folder_name = input(\"Introduce el nombre de la carpeta con las imágenes: \")\n",
    "\n",
    "# Cargar imágenes y etiquetas\n",
    "images, labels = load_images_from_folder(folder_name)\n",
    "\n",
    "# Convertir listas a arrays de numpy\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Preprocesar las imágenes\n",
    "images = images / 255.0  # Normalizar las imágenes\n",
    "\n",
    "# Codificar las etiquetas\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(images.shape[1], images.shape[2], images.shape[3])),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(lb.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save('object_recognition_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando ráfaga 1...\n",
      "1/1 [==============================] - 1s 613ms/step\n",
      "1/1 [==============================] - 0s 296ms/step\n",
      "Foto 1 de la ráfaga 1 guardada.\n",
      "1/1 [==============================] - 0s 432ms/step\n",
      "1/1 [==============================] - 0s 492ms/step\n",
      "Foto 2 de la ráfaga 1 guardada.\n",
      "1/1 [==============================] - 0s 298ms/step\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "Foto 3 de la ráfaga 1 guardada.\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "Foto 4 de la ráfaga 1 guardada.\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "Foto 5 de la ráfaga 1 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 2...\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "Foto 1 de la ráfaga 2 guardada.\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "Foto 2 de la ráfaga 2 guardada.\n",
      "1/1 [==============================] - 0s 249ms/step\n",
      "1/1 [==============================] - 0s 285ms/step\n",
      "Foto 3 de la ráfaga 2 guardada.\n",
      "1/1 [==============================] - 0s 275ms/step\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "Foto 4 de la ráfaga 2 guardada.\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "Foto 5 de la ráfaga 2 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 3...\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 248ms/step\n",
      "Foto 1 de la ráfaga 3 guardada.\n",
      "1/1 [==============================] - 0s 227ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "Foto 2 de la ráfaga 3 guardada.\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "Foto 3 de la ráfaga 3 guardada.\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "Foto 4 de la ráfaga 3 guardada.\n",
      "1/1 [==============================] - 0s 228ms/step\n",
      "1/1 [==============================] - 0s 161ms/step\n",
      "Foto 5 de la ráfaga 3 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 4...\n",
      "1/1 [==============================] - 0s 119ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "Foto 1 de la ráfaga 4 guardada.\n",
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 229ms/step\n",
      "Foto 2 de la ráfaga 4 guardada.\n",
      "1/1 [==============================] - 0s 253ms/step\n",
      "1/1 [==============================] - 0s 261ms/step\n",
      "Foto 3 de la ráfaga 4 guardada.\n",
      "1/1 [==============================] - 0s 251ms/step\n",
      "1/1 [==============================] - 0s 177ms/step\n",
      "Foto 4 de la ráfaga 4 guardada.\n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "Foto 5 de la ráfaga 4 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 5...\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "1/1 [==============================] - 0s 114ms/step\n",
      "Foto 1 de la ráfaga 5 guardada.\n",
      "1/1 [==============================] - 0s 173ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n",
      "Foto 2 de la ráfaga 5 guardada.\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "Foto 3 de la ráfaga 5 guardada.\n",
      "1/1 [==============================] - 0s 304ms/step\n",
      "1/1 [==============================] - 0s 301ms/step\n",
      "Foto 4 de la ráfaga 5 guardada.\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 195ms/step\n",
      "Foto 5 de la ráfaga 5 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 6...\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "Foto 1 de la ráfaga 6 guardada.\n",
      "1/1 [==============================] - 0s 240ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "Foto 2 de la ráfaga 6 guardada.\n",
      "1/1 [==============================] - 0s 231ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "Foto 3 de la ráfaga 6 guardada.\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 224ms/step\n",
      "Foto 4 de la ráfaga 6 guardada.\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "1/1 [==============================] - 0s 223ms/step\n",
      "Foto 5 de la ráfaga 6 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 7...\n",
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "Foto 1 de la ráfaga 7 guardada.\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "1/1 [==============================] - 0s 225ms/step\n",
      "Foto 2 de la ráfaga 7 guardada.\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "Foto 3 de la ráfaga 7 guardada.\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 176ms/step\n",
      "Foto 4 de la ráfaga 7 guardada.\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "Foto 5 de la ráfaga 7 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 8...\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "Foto 1 de la ráfaga 8 guardada.\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Foto 2 de la ráfaga 8 guardada.\n",
      "1/1 [==============================] - 0s 230ms/step\n",
      "1/1 [==============================] - 0s 222ms/step\n",
      "Foto 3 de la ráfaga 8 guardada.\n",
      "1/1 [==============================] - 0s 170ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "Foto 4 de la ráfaga 8 guardada.\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "1/1 [==============================] - 0s 226ms/step\n",
      "Foto 5 de la ráfaga 8 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 9...\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "Foto 1 de la ráfaga 9 guardada.\n",
      "1/1 [==============================] - 0s 174ms/step\n",
      "1/1 [==============================] - 0s 211ms/step\n",
      "Foto 2 de la ráfaga 9 guardada.\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 316ms/step\n",
      "Foto 3 de la ráfaga 9 guardada.\n",
      "1/1 [==============================] - 0s 246ms/step\n",
      "1/1 [==============================] - 0s 163ms/step\n",
      "Foto 4 de la ráfaga 9 guardada.\n",
      "1/1 [==============================] - 0s 180ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "Foto 5 de la ráfaga 9 guardada.\n",
      "Esperando 5 segundos antes de la siguiente ráfaga...\n",
      "Iniciando ráfaga 10...\n",
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Foto 1 de la ráfaga 10 guardada.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Cargar el modelo\n",
    "model = load_model('object_recognition_model.h5')\n",
    "\n",
    "# Crear la carpeta de reconocimiento si no existe\n",
    "if not os.path.exists('reconocimiento'):\n",
    "    os.makedirs('reconocimiento')\n",
    "\n",
    "# Iniciar la cámara\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Función para preprocesar la imagen\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (640, 480))  # Redimensionar la imagen a (480, 640)\n",
    "    preprocessed_image = resized_image / 255.0  # Normalizar la imagen\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)  # Agregar una dimensión adicional para el batch\n",
    "    return preprocessed_image\n",
    "\n",
    "# Función para tomar una ráfaga de 5 fotos\n",
    "def take_burst():\n",
    "    for i in range(5):  # Tomar 5 fotos en ráfaga\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Preprocesar la imagen\n",
    "        preprocessed_image = preprocess_image(frame)\n",
    "\n",
    "        # Realizar la predicción\n",
    "        prediction = model.predict(preprocessed_image)\n",
    "        predicted_class = np.argmax(prediction, axis=1)\n",
    "        predicted_label = lb.classes_[predicted_class[0]]\n",
    "\n",
    "        # Convertir la imagen a escala de grises y detectar bordes\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Si se encontraron contornos\n",
    "        if contours:\n",
    "            # Seleccionar el contorno más grande (el objeto principal)\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "            # Obtener el rectángulo delimitador del contorno más grande\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "            # Recortar la región de interés (ROI) del frame\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Preprocesar la ROI\n",
    "            preprocessed_roi = preprocess_image(roi)\n",
    "\n",
    "            # Realizar la predicción en la ROI\n",
    "            roi_prediction = model.predict(preprocessed_roi)\n",
    "            roi_predicted_class = np.argmax(roi_prediction, axis=1)\n",
    "            roi_predicted_label = lb.classes_[roi_predicted_class[0]]\n",
    "\n",
    "            # Si la etiqueta predicha en la ROI coincide con la etiqueta predicha en el frame completo\n",
    "            if roi_predicted_label == predicted_label:\n",
    "                # Crear una máscara para aislar el objeto\n",
    "                mask = np.zeros_like(gray)  # Crear una máscara en blanco\n",
    "                cv2.drawContours(mask, [largest_contour], -1, 255, -1)  # Dibujar el contorno en la máscara\n",
    "\n",
    "                # Aplicar la máscara para aislar el objeto\n",
    "                object_only = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "                # Recortar la imagen para guardar solo el objeto\n",
    "                object_cropped = object_only[y:y+h, x:x+w]\n",
    "\n",
    "                # Guardar la imagen del objeto recortado\n",
    "                cv2.imwrite(f\"reconocimiento/object_burst_{burst_count}_{i}.jpg\", object_cropped)\n",
    "                print(f\"Foto {i + 1} de la ráfaga {burst_count + 1} guardada.\")\n",
    "\n",
    "        # Mostrar el frame en tiempo real (opcional)\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):  # Salir si se presiona 'q'\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Contador de ráfagas\n",
    "burst_count = 0\n",
    "\n",
    "# Bucle principal\n",
    "try:\n",
    "    while True:\n",
    "        print(f\"Iniciando ráfaga {burst_count + 1}...\")\n",
    "        if not take_burst():  # Tomar una ráfaga de 5 fotos\n",
    "            break  # Salir si el usuario presiona 'q'\n",
    "\n",
    "        burst_count += 1\n",
    "        print(f\"Esperando 5 segundos antes de la siguiente ráfaga...\")\n",
    "        time.sleep(5)  # Esperar 5 segundos antes de la siguiente ráfaga\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Proceso interrumpido por el usuario.\")\n",
    "\n",
    "# Liberar la cámara y cerrar todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
